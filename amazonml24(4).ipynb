{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9380352,"sourceType":"datasetVersion","datasetId":5690489},{"sourceId":9384684,"sourceType":"datasetVersion","datasetId":5693787},{"sourceId":9407609,"sourceType":"datasetVersion","datasetId":5712066},{"sourceId":113060,"sourceType":"modelInstanceVersion","modelInstanceId":94836,"modelId":119043}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport sys\nimport os\noriginal_stdout = sys.stdout\n\n# Redirect stdout to devnull\nsys.stdout = open(os.devnull, 'w')\n\n!pip install constants craft-text-detector paddleocr paddlepaddle\n\nfrom transformers import TrOCRProcessor\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport re\n# import constants\nimport requests\nimport pandas as pd\nimport multiprocessing\nimport time\nfrom time import time as timer\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom functools import partial\nimport urllib\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n# from craft_text_detector import Craft\nfrom tqdm import tqdm\nfrom torchvision import transforms\n# from transformers import TrOCRProcessor, VisionEncoderDecoderModel\nimport cv2\nimport easyocr\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nfrom paddleocr import PaddleOCR\nfrom skimage.filters import threshold_local\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndataTrain = pd.read_csv('/kaggle/input/dataset/train.csv')\ndataTest = pd.read_csv('/kaggle/input/dataset/test.csv')\n\nsys.stdout = original_stdout  #Resume printing ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T04:40:13.644675Z","iopub.execute_input":"2024-09-16T04:40:13.645235Z","iopub.status.idle":"2024-09-16T04:42:28.875420Z","shell.execute_reply.started":"2024-09-16T04:40:13.645191Z","shell.execute_reply":"2024-09-16T04:42:28.874157Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"len(dataTest)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:12:41.231055Z","iopub.execute_input":"2024-09-16T02:12:41.231821Z","iopub.status.idle":"2024-09-16T02:12:41.240048Z","shell.execute_reply.started":"2024-09-16T02:12:41.231767Z","shell.execute_reply":"2024-09-16T02:12:41.238913Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"131187"},"metadata":{}}]},{"cell_type":"code","source":"print(dataTrain.entity_name.unique())\nprint(len(dataTrain.group_id.unique()))\nprint(dataTrain.entity_name.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProductImageDataset(Dataset):\n    def __init__(self, df, image_dir, transform=None):\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_dir, self.df.iloc[idx]['image_link'].split('/')[-1])\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        group_id = self.df.iloc[idx]['group_id']\n        entity_value = self.df.iloc[idx]['entity_value']\n        entity_name = self.df.iloc[idx]['entity_name']\n        return image, group_id,entity_name, entity_value","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:00.919441Z","iopub.execute_input":"2024-09-16T04:43:00.920351Z","iopub.status.idle":"2024-09-16T04:43:00.928057Z","shell.execute_reply.started":"2024-09-16T04:43:00.920308Z","shell.execute_reply":"2024-09-16T04:43:00.927099Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import BertModel, BertTokenizer\n\nclass EntityValuePredictor(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased'):\n        super(EntityValuePredictor, self).__init__()\n        \n        # Load BERT for embedding text inputs\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(self.bert.config.hidden_size * 2 + 1, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 2)  # Predict a single value (entity_value)\n        self.relu = nn.ReLU()\n\n    def forward(self, ocr_text, group_id, entity_name):\n        # Tokenize the text inputs\n        ocr_inputs = self.tokenizer(ocr_text, return_tensors='pt', padding=True, truncation=True)\n        entity_inputs = self.tokenizer(entity_name, return_tensors='pt', padding=True, truncation=True)\n        \n        # Get BERT embeddings\n        ocr_embedding = self.bert(**ocr_inputs)['pooler_output']\n        entity_embedding = self.bert(**entity_inputs)['pooler_output']\n        \n        # Embed the group_id\n        \n        group_id_embed = torch.tensor(group_id, dtype=torch.int32).unsqueeze(dim=0).unsqueeze(dim=0)\n        # Concatenate embeddings\n        combined_input = torch.cat([ocr_embedding, entity_embedding, group_id_embed], dim=1)\n        print(f'Comb: {combined_input.shape}')\n        # Fully connected layers for prediction\n        x = self.relu(self.fc1(combined_input))\n        x = self.relu(self.fc2(x))\n        entity_value = self.fc3(x)\n        \n        return entity_value","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/opt/conda/lib/python3.10/site-packages/craft_text_detector/models/basenet/vgg16_bn.py'\n\n# Read in the file\nwith open(file_path, 'r') as file:\n    filedata = file.read()\n\n# Replace the incorrect import statement\nfiledata = filedata.replace(\"from torchvision.models.vgg import model_urls\", \"\")\n# filedata = filedata.replace(\"model_urls['vgg16_bn'] = model_urls['vgg16_bn'].replace('https://', 'http://')\",'')\n# filedata = filedata.replace('model_urls[\"vgg16_bn\"] = model_urls[\"vgg16_bn\"].replace(\"https://\", \"http://\"','')\n\n# Write the file out again\nwith open(file_path, 'w') as file:\n    file.write(filedata)\n    \n\ntxt = \"\"\"\nall = [\n'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n'vgg19_bn', 'vgg19',\n]\n\nmodel_urls = {\n'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n}\n\"\"\"\nwith open(file_path, 'a') as file:\n    file.write(txt)\n    \n    \nfile_path = '/opt/conda/lib/python3.10/site-packages/craft_text_detector/craft_utils.py'\n\nwith open(file_path, 'r') as file:\n    filedata = file.read()\n    \nfiledata = filedata.replace(\"polys = np.array(polys)\", \"polys = np.array(polys, dtype=object)\")\n\nwith open(file_path, 'w') as file:\n    file.write(filedata)\n\nfile_path = '/opt/conda/lib/python3.10/site-packages/craft_text_detector/predict.py'\n\nwith open(file_path, 'r') as file:\n    filedata = file.read()\n    \nfiledata = filedata.replace(\"polys_as_ratio = np.array(polys_as_ratio)\", \"polys_as_ratio = np.array(polys_as_ratio, dtype=object)\")\n\nwith open(file_path, 'w') as file:\n    file.write(filedata)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:03.493188Z","iopub.execute_input":"2024-09-16T04:43:03.493865Z","iopub.status.idle":"2024-09-16T04:43:03.505205Z","shell.execute_reply.started":"2024-09-16T04:43:03.493820Z","shell.execute_reply":"2024-09-16T04:43:03.504236Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:05.736746Z","iopub.execute_input":"2024-09-16T04:43:05.737839Z","iopub.status.idle":"2024-09-16T04:43:05.776822Z","shell.execute_reply.started":"2024-09-16T04:43:05.737785Z","shell.execute_reply":"2024-09-16T04:43:05.775622Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from craft_text_detector import Craft\n# from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n\ncraft = Craft(output_dir=None, crop_type=\"box\", cuda=True)\nreader = easyocr.Reader(['en'], gpu=True)\n# paddle_ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)\n# processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:07.464239Z","iopub.execute_input":"2024-09-16T04:43:07.465043Z","iopub.status.idle":"2024-09-16T04:43:24.210724Z","shell.execute_reply.started":"2024-09-16T04:43:07.464999Z","shell.execute_reply":"2024-09-16T04:43:24.209688Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Craft text detector weight will be downloaded to /root/.craft_text_detector/weights/craft_mlt_25k.pth\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1bupFXqT-VU6Jjeul13XP7yx2Sg5IHr4J\nTo: /root/.craft_text_detector/weights/craft_mlt_25k.pth\n100%|██████████| 83.2M/83.2M [00:01<00:00, 80.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Craft text refiner weight will be downloaded to /root/.craft_text_detector/weights/craft_refiner_CTW1500.pth\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1xcE9qpJXp4ofINwXWVhhQIh9S8Z7cuGj\nTo: /root/.craft_text_detector/weights/craft_refiner_CTW1500.pth\n100%|██████████| 1.85M/1.85M [00:00<00:00, 155MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"imageNames = set(os.listdir('/kaggle/input/imagestrain/sampleTrain'))\ndef extract_image_name(image_link):\n    return image_link.split('/')[-1]\n\ndf = dataTrain.copy()\n\n# Apply the function to create a new column with the extracted image names\ndf['image_name'] = df['image_link'].apply(extract_image_name)\n# Filter rows where the image_name is in the images_in_folder set\ndf = df[df['image_name'].isin(imageNames)]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:29:42.906444Z","iopub.execute_input":"2024-09-16T02:29:42.906877Z","iopub.status.idle":"2024-09-16T02:29:43.191599Z","shell.execute_reply.started":"2024-09-16T02:29:42.906835Z","shell.execute_reply":"2024-09-16T02:29:43.190622Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()  # Convert PIL image to PyTorch Tensor\n])\n\nimage_dir = '/kaggle/input/imagestrain/sampleTrain'\noutput_dir = '/kaggle/working/output'\ntrain_dataset = ProductImageDataset(df, image_dir, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n# model = EntityValuePredictor()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T20:57:09.254460Z","iopub.execute_input":"2024-09-15T20:57:09.254883Z","iopub.status.idle":"2024-09-15T20:57:09.261398Z","shell.execute_reply.started":"2024-09-15T20:57:09.254844Z","shell.execute_reply":"2024-09-15T20:57:09.260389Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nfrom math import atan2, degrees\n\ndef extract_structured_text3(image):\n#     image = preprocess_image3(image)\n#     print(f'Image: {image.shape}')\n    prediction_result = craft.detect_text(image)\n#     debug_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n#     debug_image = Image.fromarray(image)\n#     draw = ImageDraw.Draw(debug_image)\n    structured_text = []\n    boxes = prediction_result[\"boxes\"]\n    for box in boxes:\n#         draw.polygon([tuple(point) for point in box], outline=(255, 0, 0), width=5)\n        roi = get_cropped3(image, box)\n#         angle = get_box_rotation_angle3(box)\n#         if angle != 0:\n# #             print(f'Angle:{angle}')\n#             roi = get_rotated_roi3(image,box,angle)\n#         text = extract_text_from_roi(roi)\n#         text = pytesseract.image_to_string(img, lang='eng')\n        result = reader.readtext(np.array(roi))\n        if result:\n#             draw.text((box[0][0], box[0][1] - 10), result, fill=(0, 255, 0))\n            structured_text.append(result[0][1])\n        \n#         text = paddle_ocr.ocr(np.array(roi), rec=True)\n#         if text:\n# #             text = [entry[1][0] for entry in text]  # Get the recognized text only\n# #             structured_text.extend(text)  # Add to the structured text list\n#             draw.text((box[0][0], box[0][1] - 10), text, fill=(0, 255, 0))\n#             for result in text:\n#                 if result:\n#                     for line in result:\n#                         if line:\n#                             text = line[1][0]  # Extracting text\n#                             structured_text.append(text)  # Collecting recognized text\n    return filterNum3(structured_text)\n\ndef contains_numbers3(string):\n    return any(char.isdigit() for char in string)\n\ndef filterNum3(rowRes):\n    temp = []\n    for r in rowRes:\n#         for s in r:\n        if contains_numbers3(r):\n            temp.append(r)\n    return temp\n\n# def get_rotation_angle(box):\n#     \"\"\"Calculates the rotation angle of the box.\"\"\"\n#     print(f'Box: {box}')\n#     p1, p2 = box[0], box[1]  # Taking two points of the box\n#     angle = atan2(p2[1] - p1[1], p2[0] - p1[0])\n#     return degrees(angle)\n\n# def rotate_image(image, angle):\n#     \"\"\"Rotates the image by the given angle.\"\"\"\n# #     pil_img = Image.fromarray(np.array(image))\n#     image = image.rotate(angle, expand=True)\n#     return image\n\ndef get_rotated_roi3(image, box, angle):\n    \"\"\"Extracts and rotates the region of interest from the image.\"\"\"\n    # Get the four points of the box\n    rect = cv2.minAreaRect(np.int0(box))\n    box_points = cv2.boxPoints(rect)\n    box_points = np.int0(box_points)\n    \n    # Apply affine transformation to correct rotation\n    width = int(rect[1][0])\n    height = int(rect[1][1])\n    src_pts = box_points.astype(\"float32\")\n    dst_pts = np.array([[0, height-1],\n                        [0, 0],\n                        [width-1, 0],\n                        [width-1, height-1]], dtype=\"float32\")\n\n    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n    warped = cv2.warpPerspective(image, M, (width, height))\n    \n    return Image.fromarray(warped).convert('RGB')\n\ndef get_box_rotation_angle3(box):\n    \"\"\"Calculates the rotation angle of the box using all four points.\"\"\"\n    # Calculate angle from first two points (this will handle rotations better)\n    rect = cv2.minAreaRect(np.int0(box))\n    angle = rect[-1]  # Angle returned by minAreaRect\n    if angle < -45:\n        angle += 90\n    return angle\n\ndef preprocess_image3(image):\n    \"\"\" Preprocessing steps: scaling, rotation, denoising, and contrast enhancement \"\"\"\n    # Convert image to grayscale\n    min_size = 1500  # You can adjust this value\n    h, w = image.shape[:2]\n    if max(h, w) < min_size:\n        scale = min_size / max(h, w)\n        image = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n#     image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n# #     # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n#     image = clahe.apply(image)\n#     image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n    return image\n\n# def get_rotated_roi(image, box):\n#     rect = cv2.minAreaRect(np.array(box[0]).astype(np.float32))\n#     angle = rect[2]\n#     rows, cols = image.shape[0], image.shape[1]\n#     M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n#     rotated_image = cv2.warpAffine(image, M, (cols, rows))\n    \n#     box = cv2.boxPoints(rect)\n#     box = np.int0(box)\n    \n#     width = int(rect[1][0])\n#     height = int(rect[1][1])\n#     src_pts = box.astype(\"float32\")\n#     dst_pts = np.array([[0, height-1], [0, 0], [width-1, 0], [width-1, height-1]], dtype=\"float32\")\n#     M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n#     warped = cv2.warpPerspective(rotated_image, M, (width, height))\n    \n#     return Image.fromarray(warped).convert('RGB')\n\ndef get_cropped3(image, box):\n    box = np.int0(box)\n    x_min = np.min(box[:, 0])\n    y_min = np.min(box[:, 1])\n    x_max = np.max(box[:, 0])\n    y_max = np.max(box[:, 1])\n    \n    # Crop the region of interest\n    cropped_roi = image[y_min:y_max, x_min:x_max]\n    \n    return Image.fromarray(cropped_roi).convert('RGB')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:24.212795Z","iopub.execute_input":"2024-09-16T04:43:24.213363Z","iopub.status.idle":"2024-09-16T04:43:24.231883Z","shell.execute_reply.started":"2024-09-16T04:43:24.213327Z","shell.execute_reply":"2024-09-16T04:43:24.230606Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def extract_structured_text(image):\n    image = preprocess_image(image)\n    result = paddle_ocr.ocr(image, rec=False, cls=False)\n#     print(f'Paddle OCR result:{result}')\n    boxes = [line for line in result]\n    if boxes != [None]:\n        sboxes = sorted(boxes, key=lambda box: (box[0][1], box[0][0]))\n    #     gboxes = group_boxes_by_row(sboxes)\n        structured_text = []\n        rowRes = []\n        for row in sboxes:\n            row_text = []\n            for box in row:\n                # Extract the region of interest (ROI)\n                points = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n                rect = cv2.boundingRect(points)\n                x, y, w, h = rect\n                roi = image[y:y+h, x:x+w]\n                angle = get_box_rotation_angle3(box)\n                if angle != 0:\n        #             print(f'Angle:{angle}')\n                    roi = get_rotated_roi3(image,box,angle)\n    #             roi.save(\"temp_image.jpg\")\n                # Recognize text using EasyOCR\n                result = reader.readtext(np.array(roi))\n                if result:\n                    row_text.append(result[0][1])  # Append recognized text\n#             print(f'Row result: {row_text}')\n            rowRes.append(row_text)\n            structured_text.append(' '.join(row_text))\n#         print(f'rowRes: {rowRes}')\n#         return structured_text\n        return filterNum(rowRes)\n\ndef get_box_rotation_angle3(box):\n    \"\"\"Calculates the rotation angle of the box using all four points.\"\"\"\n    # Calculate angle from first two points (this will handle rotations better)\n    rect = cv2.minAreaRect(np.int0(box))\n    angle = rect[-1]  # Angle returned by minAreaRect\n    if angle < -45:\n        angle += 90\n    return angle\n\ndef preprocess_image3(image):\n    \"\"\" Preprocessing steps: scaling, rotation, denoising, and contrast enhancement \"\"\"\n    # Convert image to grayscale\n    min_size = 1500  # You can adjust this value\n    h, w = image.shape[:2]\n    if max(h, w) < min_size:\n        scale = min_size / max(h, w)\n        image = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n    \ndef group_boxes_by_row(boxes, height_threshold=10):\n    rows = []\n    current_row = [boxes[0]]\n    for box in boxes[1:]:\n        if abs(box[0][1] - current_row[0][0][1]) < height_threshold:\n            current_row.append(box)\n        else:\n            rows.append(current_row)\n            current_row = [box]\n    rows.append(current_row)\n    return rows\n\ndef extract_text_easyocr(image_url: str, gpu: bool = True) -> str:\n    # Initialize the reader (set GPU=True for GPU usage, False for CPU)\n    reader = easyocr.Reader(['en'], gpu=gpu)\n\n    # Fetch the image from the URL\n    response = requests.get(image_url)\n    img = Image.open(BytesIO(response.content))\n\n    # Save image to a file since EasyOCR works with file paths\n    img.save(\"temp_image.jpg\")\n\n    # Extract text using EasyOCR\n    result = reader.readtext('temp_image.jpg', detail=0)\n    \n    print()\n\n    # Return the extracted text as a string\n    return \" \".join(result)\n\ndef contains_numbers(string):\n    return any(char.isdigit() for char in string)\n\ndef filterNum(rowRes):\n    temp = []\n    for r in rowRes:\n        for s in r:\n            if contains_numbers(s):\n                temp.append(s)\n    return ', '.join(temp)\n\ndef preprocess_image(image):\n    \"\"\" Preprocessing steps: scaling, rotation, denoising, and contrast enhancement \"\"\"\n    # Convert image to grayscale\n    gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    enhanced_image = clahe.apply(gray)\n    # Apply adaptive thresholding to make text more prominent\n#     T = threshold_local(gray, 11, offset=10, method=\"gaussian\")\n#     binary_image = (gray > T).astype(\"uint8\") * 255\n    # Denoise the image\n#     denoised_image = cv2.fastNlMeansDenoising(binary_image, h=30)\n    # Skew correction (detecting the angle and rotating)\n#     coords = np.column_stack(np.where(binary_image > 0))\n#     angle = cv2.minAreaRect(coords)[-1]\n#     if angle < -45:\n#         angle = -(90 + angle)\n#     else:\n#         angle = -angle\n#     # Rotate the image to correct skew\n#     (h, w) = denoised_image.shape[:2]\n#     center = (w // 2, h // 2)\n#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n#     rotated_image = cv2.warpAffine(denoised_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return enhanced_image","metadata":{"execution":{"iopub.status.busy":"2024-09-15T23:18:50.482679Z","iopub.execute_input":"2024-09-15T23:18:50.483377Z","iopub.status.idle":"2024-09-15T23:18:50.503374Z","shell.execute_reply.started":"2024-09-15T23:18:50.483323Z","shell.execute_reply":"2024-09-15T23:18:50.502547Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!sudo apt install tesseract-ocr\n!sudo apt install libtesseract-dev -y","metadata":{"execution":{"iopub.status.busy":"2024-09-15T23:18:50.504351Z","iopub.execute_input":"2024-09-15T23:18:50.504636Z","iopub.status.idle":"2024-09-15T23:18:59.677176Z","shell.execute_reply.started":"2024-09-15T23:18:50.504605Z","shell.execute_reply":"2024-09-15T23:18:59.675918Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\n0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  libarchive-dev libleptonica-dev\nThe following NEW packages will be installed:\n  libarchive-dev libleptonica-dev libtesseract-dev\n0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\nNeed to get 3744 kB of archives.\nAfter this operation, 16.0 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.1 [582 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1562 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1600 kB]\nFetched 3744 kB in 1s (4777 kB/s)          \u001b[0m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libarchive-dev:amd64.\n(Reading database ... 123110 files and directories currently installed.)\nPreparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libleptonica-dev.\nPreparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libleptonica-dev (1.82.0-3build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libtesseract-dev:amd64.\nPreparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Setting up libleptonica-dev (1.82.0-3build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Processing triggers for man-db (2.10.2-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, BitsAndBytesConfig\nimport torch\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16\n)\nentity_name = 'item_weight'\nmodel_id = \"llava-hf/llava-1.5-7b-hf\"\npipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n# pipe = pipeline(\"image-to-text\", model=model_id, device=device)\nprompt = f\"\"\"\nUSER: <image>\\n\n\nAnalyze the product image {img} and focus on finding the width measurement.\n\nImportant instructions:\n1. Look for text indicating width, which may be tilted, in small font, or appear multiple times.\n2. The measurement should be of type {entity_name}.\n3. If multiple width values are present, choose the most appropriate one.\n4. Ignore any irrelevant text or measurements.\n5. The expected output should be in 'value unit' format\n\nYour task:\n1. Identify all instances of {entity_name} measurements in the image.\n2. Select the most appropriate width value in {entity_name} units.\n3. Respond with only the numerical value and unit in this format: [number] unit\n\nFor example, a correct response would be: 21.5 centimetre\n\nRemember to carefully examine the entire image, as the relevant information might be in an unexpected location or format.\n\n\\nASSISTANT:\"\n\"\"\"\n\nprompt = f\"\"\"\nUSER: <image>\\n\nGiven an image of a product, the goal is to extract the correct entity_value based on the provided entity_name and group_id. The text value in the image may be tilted, in a small font, or there may be multiple similar values. You need to select the value that corresponds to the right units based on the entity_name. In case of multiple similar values, choose the most appropriate one.\n\nInputs:\n\nimage_link: {img}\nentity_name: {entity_name}\nExpected Output:\n\nentity_value: value unit\n\\nASSISTANT:\"\n\"\"\"\n\noutputs = pipe(img, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\nprint(outputs[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-09-15T21:12:58.451032Z","iopub.execute_input":"2024-09-15T21:12:58.452025Z","iopub.status.idle":"2024-09-15T21:13:15.479932Z","shell.execute_reply.started":"2024-09-15T21:12:58.451976Z","shell.execute_reply":"2024-09-15T21:13:15.478903Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f82859f98045a9852af6268a9f728d"}},"metadata":{}},{"name":"stdout","text":"\nUSER:  \n\nGiven an image of a product, the goal is to extract the correct entity_value based on the provided entity_name and group_id. The text value in the image may be tilted, in a small font, or there may be multiple similar values. You need to select the value that corresponds to the right units based on the entity_name. In case of multiple similar values, choose the most appropriate one.\n\nInputs:\n\nimage_link: <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=661x580 at 0x7D7685C866E0>\nentity_name: item_weight\nExpected Output:\n\nentity_value: value unit\n\nASSISTANT:\"\n\nIn the image, there is a blue box with a white interior, which is a battery. The battery is labeled with the text \"26.15 x 12.5 x 25.5 mt\", which is the correct entity\\_value based on the entity\\_name \"item\\_weight\". The text is in a small font and might be slightly tilted, but it is still clear enough to read. The battery is 26.15 centimeters long, 12.5 centimeters wide, and 25.5 centimeters high, which is the correct unit of measurement based on the provided entity\\_id.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes-cuda113\n!pip install bitsandbytes==0.43.3","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef extract_value_and_unit(craft_list, entity_name, entity_unit_map):\n    unit_patterns = {\n        'centimetre': r'(?:^|\\s)(?:cm|centimetre|centimeter)(?:$|\\s)',\n        'foot': r'(?:^|\\s)(?:ft|foot|feet)(?:$|\\s)',\n        'inch': r'(?:^|\\s)(?:in|inch|inches|\")(?:$|\\s)',\n        'metre': r'(?:^|\\s)(?:m|metre|meter)(?:$|\\s)',\n        'millimetre': r'(?:^|\\s)(?:mm|millimetre|millimeter)(?:$|\\s)',\n        'yard': r'(?:^|\\s)(?:yd|yard)(?:$|\\s)',\n        'gram': r'(?:^|\\s)(?:g|gram)(?:$|\\s)',\n        'kilogram': r'(?:^|\\s)(?:kg|kilogram)(?:$|\\s)',\n        'microgram': r'(?:^|\\s)(?:µg|mcg|microgram)(?:$|\\s)',\n        'milligram': r'(?:^|\\s)(?:mg|milligram)(?:$|\\s)',\n        'ounce': r'(?:^|\\s)(?:oz|ounce)(?:$|\\s)',\n        'pound': r'(?:^|\\s)(?:lb|pound)(?:$|\\s)',\n        'ton': r'(?:^|\\s)(?:ton)(?:$|\\s)',\n        'kilovolt': r'(?:^|\\s)(?:kv|kilovolt)(?:$|\\s)',\n        'millivolt': r'(?:^|\\s)(?:mv|millivolt)(?:$|\\s)',\n        'volt': r'(?:^|\\s)(?:v|volt)(?:$|\\s)',\n        'kilowatt': r'(?:^|\\s)(?:kw|kilowatt)(?:$|\\s)',\n        'watt': r'(?:^|\\s)(?:w|watt)(?:$|\\s)',\n        'centilitre': r'(?:^|\\s)(?:cl|centilitre|centiliter)(?:$|\\s)',\n        'cubic foot': r'(?:^|\\s)(?:cu ft|cubic foot|cubic feet)(?:$|\\s)',\n        'cubic inch': r'(?:^|\\s)(?:cu in|cubic inch)(?:$|\\s)',\n        'cup': r'(?:^|\\s)(?:cup)(?:$|\\s)',\n        'decilitre': r'(?:^|\\s)(?:dl|decilitre|deciliter)(?:$|\\s)',\n        'fluid ounce': r'(?:^|\\s)(?:fl oz|fluid ounce)(?:$|\\s)',\n        'gallon': r'(?:^|\\s)(?:gal|gallon)(?:$|\\s)',\n        'imperial gallon': r'(?:^|\\s)(?:imp gal|imperial gallon)(?:$|\\s)',\n        'litre': r'(?:^|\\s)(?:l|litre|liter)(?:$|\\s)',\n        'microlitre': r'(?:^|\\s)(?:µl|mcl|microlitre|microliter)(?:$|\\s)',\n        'millilitre': r'(?:^|\\s)(?:ml|millilitre|milliliter)(?:$|\\s)',\n        'pint': r'(?:^|\\s)(?:pt|pint)(?:$|\\s)',\n        'quart': r'(?:^|\\s)(?:qt|quart)(?:$|\\s)'\n    }\n    \n    all_patterns = '|'.join(f'({pattern})' for pattern in unit_patterns.values())\n    \n    matching_results = []\n    highest_value = float('-inf')\n    \n    for item in craft_list:\n        matches = re.finditer(rf'(\\d+(?:\\.\\d+)?)\\s*({all_patterns})', item, re.IGNORECASE)\n        for match in matches:\n            value = float(match.group(1))\n            matched_unit = match.group(2).strip()\n            \n            standard_unit = next((unit for unit, pattern in unit_patterns.items() \n                                  if re.match(pattern, matched_unit, re.IGNORECASE)), None)\n            \n            if standard_unit in entity_unit_map.get(entity_name, set()):\n                matching_results.append((value, standard_unit))\n            \n            highest_value = max(highest_value, value)\n    \n    return matching_results, highest_value\n\ndef format_entity_value(value, unit):\n    if unit in ['foot', 'inch']:\n        return f\"{value} {unit}{'es' if value != 1 and unit == 'inch' else ''}\"\n    else:\n        return f\"{value} {unit}\"\n\ndef process_craft_outputs(craft_outputs, entity_name, entity_unit_map):\n    all_matching_results = []\n    highest_overall_value = float('-inf')\n    \n    for craft_list in craft_outputs:\n        matching_results, highest_value = extract_value_and_unit(craft_list, entity_name, entity_unit_map)\n        all_matching_results.extend(matching_results)\n        highest_overall_value = max(highest_overall_value, highest_value)\n    \n    if all_matching_results:\n        # If there are matching results, return the highest value among them\n        highest_matching_value = max(all_matching_results, key=lambda x: x[0])\n        return format_entity_value(*highest_matching_value)\n    elif highest_overall_value != float('-inf'):\n        # If no matching results, but we found numerical values, use the highest with the default unit\n        default_unit = next(iter(entity_unit_map.get(entity_name, [])), None)\n        if default_unit:\n            return format_entity_value(highest_overall_value, default_unit)\n    \n    return None\n\n# Example usage\nentity_unit_map = {\n    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'voltage': {'kilovolt', 'millivolt', 'volt'},\n    'wattage': {'kilowatt', 'watt'},\n    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n}\n\n# Test cases\ntest_cases = [\n    ([['UT-50', '5A', '25w'], ['25 watts', '5 amps'], ['25 W']], 'wattage'),\n    ([['Length: 10\"', 'Width: 5 in'], ['10 inches length', '5 inch width'], ['L: 10\"', 'W: 5\"']], 'width'),\n    ([['Weight: 2.5 kg', 'Color: Blue'], ['2.5 kilograms'], ['Mass: 2500g']], 'item_weight'),\n    ([['Capacity: 500ml', 'Height: 20cm'], ['500 milliliters'], ['0.5 L']], 'item_volume'),\n    ([['Power: 1.5 kilowatts', 'Voltage: 220V'], ['1500W'], ['1.5 kW']], 'wattage'),\n    ([['Dimensions: 6 feet by 3 feet', 'Material: Wood'], ['6 ft width'], ['Width: 72 inches']], 'width'),\n    ([['Size: 10', 'Color: Red'], ['Length: 15'], ['Measurement: 20']], 'width')  # No matching unit\n]\n\nfor craft_outputs, entity_name in test_cases:\n    result = process_craft_outputs(craft_outputs, entity_name, entity_unit_map)\n    print(f\"CRAFT outputs: {craft_outputs}\")\n    print(f\"Entity Name: {entity_name}\")\n    print(f\"Entity Value: {result}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:31:19.783082Z","iopub.execute_input":"2024-09-16T02:31:19.783489Z","iopub.status.idle":"2024-09-16T02:31:19.810357Z","shell.execute_reply.started":"2024-09-16T02:31:19.783452Z","shell.execute_reply":"2024-09-16T02:31:19.809263Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"CRAFT outputs: [['UT-50', '5A', '25w'], ['25 watts', '5 amps'], ['25 W']]\nEntity Name: wattage\nEntity Value: 25.0 watt\n\nCRAFT outputs: [['Length: 10\"', 'Width: 5 in'], ['10 inches length', '5 inch width'], ['L: 10\"', 'W: 5\"']]\nEntity Name: width\nEntity Value: 10.0 inches\n\nCRAFT outputs: [['Weight: 2.5 kg', 'Color: Blue'], ['2.5 kilograms'], ['Mass: 2500g']]\nEntity Name: item_weight\nEntity Value: 2.5 kilogram\n\nCRAFT outputs: [['Capacity: 500ml', 'Height: 20cm'], ['500 milliliters'], ['0.5 L']]\nEntity Name: item_volume\nEntity Value: 0.5 litre\n\nCRAFT outputs: [['Power: 1.5 kilowatts', 'Voltage: 220V'], ['1500W'], ['1.5 kW']]\nEntity Name: wattage\nEntity Value: 1.5 kilowatt\n\nCRAFT outputs: [['Dimensions: 6 feet by 3 feet', 'Material: Wood'], ['6 ft width'], ['Width: 72 inches']]\nEntity Name: width\nEntity Value: 72.0 inches\n\nCRAFT outputs: [['Size: 10', 'Color: Red'], ['Length: 15'], ['Measurement: 20']]\nEntity Name: width\nEntity Value: None\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\ndef extract_value_and_unit(craft_list, entity_name, entity_unit_map):\n    # Define unit patterns and their corresponding standard units\n    unit_patterns = {\n        'centimetre': r'cm|centimetre|centimeter',\n        'foot': r'ft|foot|feet',\n        'inch': r'in|inch|\"',\n        'metre': r'm|metre|meter',\n        'millimetre': r'mm|millimetre|millimeter',\n        'yard': r'yd|yard',\n        'gram': r'g|gram',\n        'kilogram': r'kg|kilogram',\n        'microgram': r'µg|mcg|microgram',\n        'milligram': r'mg|milligram',\n        'ounce': r'oz|ounce',\n        'pound': r'lb|pound',\n        'ton': r'ton',\n        'kilovolt': r'kv|kilovolt',\n        'millivolt': r'mv|millivolt',\n        'volt': r'v|volt',\n        'kilowatt': r'kw|kilowatt',\n        'watt': r'w|watt',\n        'centilitre': r'cl|centilitre|centiliter',\n        'cubic foot': r'cu ft|cubic foot|cubic feet',\n        'cubic inch': r'cu in|cubic inch',\n        'cup': r'cup',\n        'decilitre': r'dl|decilitre|deciliter',\n        'fluid ounce': r'fl oz|fluid ounce',\n        'gallon': r'gal|gallon',\n        'imperial gallon': r'imp gal|imperial gallon',\n        'litre': r'l|litre|liter',\n        'microlitre': r'µl|mcl|microlitre|microliter',\n        'millilitre': r'ml|millilitre|milliliter',\n        'pint': r'pt|pint',\n        'quart': r'qt|quart'\n    }\n    \n    # Combine all patterns\n    all_patterns = '|'.join(f'({pattern})' for pattern in unit_patterns.values())\n    \n    # Find a matching item in CRAFT list\n    for item in craft_list:\n        match = re.search(rf'(\\d+(?:\\.\\d+)?)\\s*({all_patterns})', item, re.IGNORECASE)\n        if match:\n            value = float(match.group(1))\n            matched_unit = match.group(2)\n            \n            # Find the standard unit name\n            standard_unit = next((unit for unit, pattern in unit_patterns.items() \n                                  if re.match(pattern, matched_unit, re.IGNORECASE)), None)\n            \n            if standard_unit in entity_unit_map.get(entity_name, set()):\n                return value, standard_unit\n            \n    # If no recognized unit is found, look for any numerical value\n    for item in craft_list:\n        match = re.search(r'(\\d+(?:\\.\\d+)?)', item)\n        if match:\n            value = float(match.group(1))\n            # Return the default unit for the entity type, or None if not specified\n            default_unit = next(iter(entity_unit_map.get(entity_name, [])), None)\n            return value, default_unit\n    \n    return None, None\n\ndef format_entity_value(value, unit):\n    if value is None or unit is None:\n        return None\n    \n    if unit is None:\n        return f\"{value}\"\n    \n    # Special formatting for certain units\n    if unit in ['foot', 'inch']:\n        return f\"{value} {unit}\" if value != 1 else f\"{value} {unit}\"\n    else:\n        return f\"{value} {unit}\" if value != 1 else f\"{value} {unit}\"\n\ndef process_craft_list(craft_list, entity_name, entity_unit_map):\n    value, unit = extract_value_and_unit(craft_list, entity_name, entity_unit_map)\n    if value is not None and unit is not None:\n        return format_entity_value(value, unit)\n    return None\n\n# Example usage\nentity_unit_map = {\n    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'voltage': {'kilovolt', 'millivolt', 'volt'},\n    'wattage': {'kilowatt', 'watt'},\n    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon','millilitre' ,'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n}\n\n# Test cases\ntest_cases = [\n    (['UT-50', '5A', '25w'], 'wattage'),\n    (['Length: 10\"', 'Width: 5 in'], 'width'),\n    (['Weight: 2.5 kg', 'Color: Blue'], 'item_weight'),\n    (['Capacity: 500ml', 'Height: 20cm'], 'item_volume'),\n    (['Power: 1.5 kilowatts', 'Voltage: 220V'], 'wattage'),\n    (['Dimensions: 6 feet by 3 feet', 'Material: Wood'], 'width')\n]\n\nfor craft_list, entity_name in test_cases:\n    result = process_craft_list(craft_list, entity_name, entity_unit_map)\n    print(f\"CRAFT: {craft_list}\")\n    print(f\"Entity Name: {entity_name}\")\n    print(f\"Entity Value: {result}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:28.214040Z","iopub.execute_input":"2024-09-16T04:43:28.214963Z","iopub.status.idle":"2024-09-16T04:43:28.240881Z","shell.execute_reply.started":"2024-09-16T04:43:28.214920Z","shell.execute_reply":"2024-09-16T04:43:28.239838Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"CRAFT: ['UT-50', '5A', '25w']\nEntity Name: wattage\nEntity Value: 25.0 watt\n\nCRAFT: ['Length: 10\"', 'Width: 5 in']\nEntity Name: width\nEntity Value: 10.0 inch\n\nCRAFT: ['Weight: 2.5 kg', 'Color: Blue']\nEntity Name: item_weight\nEntity Value: 2.5 kilogram\n\nCRAFT: ['Capacity: 500ml', 'Height: 20cm']\nEntity Name: item_volume\nEntity Value: 500.0 fluid ounce\n\nCRAFT: ['Power: 1.5 kilowatts', 'Voltage: 220V']\nEntity Name: wattage\nEntity Value: 1.5 kilowatt\n\nCRAFT: ['Dimensions: 6 feet by 3 feet', 'Material: Wood']\nEntity Name: width\nEntity Value: 6.0 foot\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# index                                                          0\n# image_link     https://m.media-amazon.com/images/I/110EibNycl...\n# group_id                                                  156839\n# entity_name                                               height","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm\nimport easyocr\n\n# Assuming you have CRAFT and your custom functions imported\n# import craft\n# from your_module import extract_value_and_unit, entity_unit_map\n\n# Use GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize EasyOCR reader\n\n# Define standard size for all images\nSTANDARD_SIZE = (256, 256)  # You can adjust this based on your needs\n\nclass ImageDataset(Dataset):\n    def __init__(self, dataframe, img_dir):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        img_name = row[1].split('/')[-1]\n        img_path = os.path.join(self.img_dir, img_name)\n        \n        if os.path.exists(img_path):\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, STANDARD_SIZE, interpolation=cv2.INTER_AREA)\n            return row[0], img, row[3]\n        else:\n            return row[0], None, row[3]\n\ndef extract_structured_text(image):\n    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n    prediction_result = craft.detect_text(image)\n    structured_text = []\n    for box in prediction_result[\"boxes\"]:\n        roi = get_cropped3(image, box)\n        result = reader.readtext(np.array(roi))\n        if result:\n            structured_text.append(result[0][1])\n    return filter_num(structured_text)\n\ndef contains_numbers(string):\n    return any(char.isdigit() for char in string)\n\ndef filter_num(row_res):\n    return [r for r in row_res if contains_numbers(r)]\n\ndef get_cropped3(image, box):\n    box = np.int0(box)\n    x_min = np.min(box[:, 0])\n    y_min = np.min(box[:, 1])\n    x_max = np.max(box[:, 0])\n    y_max = np.max(box[:, 1])\n    \n    # Crop the region of interest\n    cropped_roi = image[y_min:y_max, x_min:x_max]\n    \n    return Image.fromarray(cropped_roi).convert('RGB')\n\ndef process_batch(batch):\n    indices, images, entity_types = batch\n    results = []\n    for idx, img, entity_type in zip(indices, images, entity_types):\n        if img is not None:\n            res = extract_structured_text(img)\n            fres = extract_value_and_unit(res, entity_type, entity_unit_map)\n            results.append([idx, fres])\n        else:\n            results.append([idx, \"\"])\n    return results\n\ndef main():\n    # Load your data\n    dataTest = pd.read_csv('/kaggle/input/dataset/test.csv')  # Adjust path as needed\n    \n    # Create dataset and dataloader\n    dataset = ImageDataset(dataTest, '/kaggle/input/sampletest/test2')\n    dataloader = DataLoader(dataset, batch_size=128, num_workers=0, pin_memory=True)\n    \n    results = []\n    \n    # Process batches\n    for batch in tqdm(dataloader, desc=\"Processing batches\"):\n        batch_results = process_batch(batch)\n        results.extend(batch_results)\n    \n    # Create final DataFrame\n    df = pd.DataFrame(results, columns=['index', 'prediction'])\n    \n    # Save results\n    df.to_csv('/kaggle/working/output.csv', index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T03:35:22.740268Z","iopub.execute_input":"2024-09-16T03:35:22.740672Z","iopub.status.idle":"2024-09-16T04:18:26.654666Z","shell.execute_reply.started":"2024-09-16T03:35:22.740631Z","shell.execute_reply":"2024-09-16T04:18:26.653226Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/1025 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33eac664058c40ad9742715a15efac84"}},"metadata":{}},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"dflist = []\nfor i,r in dataTest[:5000].iterrows():\n    if i%100 == 0:\n        print('Ahoy')\n    img_name = r[1].split('/')[-1]\n    img = Image.open(f'/kaggle/input/sampletest/test2/{img_name}')\n    if img_name in os.listdir('/kaggle/input/sampletest/test2') and img:\n#         print(img)\n        res3 = extract_structured_text3(np.array(img))\n#         res = extract_structured_text(np.array(img))\n#         res2 = filterNum3(reader.readtext(img, detail=0))\n#         res4 = pytesseract.image_to_string(img, lang='eng').strip()\n        fres = extract_value_and_unit(res3,r[3],entity_unit_map)\n        dflist.append([r[0],fres])\n    else:\n        dflist.append([r[0],\"\"])\ndf = pd.DataFrame(dflist, columns=['index', 'prediction'])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:19:25.979982Z","iopub.execute_input":"2024-09-16T04:19:25.980696Z","iopub.status.idle":"2024-09-16T04:19:28.266551Z","shell.execute_reply.started":"2024-09-16T04:19:25.980655Z","shell.execute_reply":"2024-09-16T04:19:28.265190Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Ahoy\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sampletest/test2/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sampletest/test2\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m img:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         print(img)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m         res3 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_structured_text3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         res = extract_structured_text(np.array(img))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         res2 = filterNum3(reader.readtext(img, detail=0))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         res4 = pytesseract.image_to_string(img, lang='eng').strip()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         fres \u001b[38;5;241m=\u001b[39m extract_value_and_unit(res3,r[\u001b[38;5;241m3\u001b[39m],entity_unit_map)\n","Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mextract_structured_text3\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_structured_text3\u001b[39m(image):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     image = preprocess_image3(image)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     print(f'Image: {image.shape}')\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mcraft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     debug_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     debug_image = Image.fromarray(image)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     draw = ImageDraw.Draw(debug_image)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     structured_text \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/craft_text_detector/__init__.py:131\u001b[0m, in \u001b[0;36mCraft.detect_text\u001b[0;34m(self, image, image_path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     image \u001b[38;5;241m=\u001b[39m image_path\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# perform prediction\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcraft_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcraft_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefine_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlong_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# arange regions\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/craft_text_detector/predict.py:80\u001b[0m, in \u001b[0;36mget_prediction\u001b[0;34m(image, craft_net, refine_net, text_threshold, link_threshold, low_text, cuda, long_size, poly)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch_utils\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     79\u001b[0m         y_refiner \u001b[38;5;241m=\u001b[39m refine_net(y, feature)\n\u001b[0;32m---> 80\u001b[0m     score_link \u001b[38;5;241m=\u001b[39m \u001b[43my_refiner\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     81\u001b[0m refinenet_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m     82\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\nimport numpy as np\n\ndef process_and_save_batches(dataTest, batch_size, entity_unit_map, output_file):\n    total_rows = len(dataTest)\n    dflist = []\n    \n    # Initialize or clear the output CSV file\n    df = pd.DataFrame(columns=['index', 'prediction'])\n    df.to_csv(output_file, index=False, mode='w')\n    \n    # Process in batches of 500\n    for start_idx in range(0, total_rows, batch_size):\n        batch = dataTest[start_idx:start_idx + batch_size]\n        print(f'Processing batch {start_idx} to {start_idx + len(batch)}')\n        \n        # Process each row in the batch\n        for i, r in tqdm(batch.iterrows(), total=len(batch), desc=f\"Processing batch {start_idx}\"):\n            img_name = r[1].split('/')[-1]\n            img_path = f'/kaggle/input/sampletest/test2/{img_name}'\n            if os.path.exists(img_path):\n                img = Image.open(img_path)\n                res3 = extract_structured_text3(np.array(img))\n                fres = extract_value_and_unit(res3, r[3], entity_unit_map)\n                dflist.append([r[0], fres])\n            else:\n                dflist.append([r[0], \"\"])\n        \n        # Save batch results to CSV\n        df_batch = pd.DataFrame(dflist, columns=['index', 'prediction'])\n        df_batch.to_csv(output_file, index=False, mode='a', header=False)\n        \n        # Clear dflist for the next batch\n        dflist.clear()\n\n# Set the batch size and output file\nbatch_size = 500\noutput_file = '/kaggle/working/final_output.csv'\n\n# Call the function\nprocess_and_save_batches(dataTest, batch_size, entity_unit_map, output_file)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:43:40.199997Z","iopub.execute_input":"2024-09-16T04:43:40.200679Z","iopub.status.idle":"2024-09-16T06:17:14.520404Z","shell.execute_reply.started":"2024-09-16T04:43:40.200637Z","shell.execute_reply":"2024-09-16T06:17:14.518034Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Processing batch 0 to 500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 0: 100%|██████████| 500/500 [03:14<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 500 to 1000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 500: 100%|██████████| 500/500 [03:21<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 1000 to 1500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 1000: 100%|██████████| 500/500 [03:23<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 1500 to 2000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 1500: 100%|██████████| 500/500 [03:56<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 2000 to 2500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 2000: 100%|██████████| 500/500 [04:00<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 2500 to 3000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 2500: 100%|██████████| 500/500 [03:58<00:00,  2.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 3000 to 3500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 3000: 100%|██████████| 500/500 [04:01<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 3500 to 4000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 3500: 100%|██████████| 500/500 [03:56<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 4000 to 4500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 4000: 100%|██████████| 500/500 [04:03<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 4500 to 5000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 4500: 100%|██████████| 500/500 [04:04<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 5000 to 5500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 5000: 100%|██████████| 500/500 [03:59<00:00,  2.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 5500 to 6000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 5500: 100%|██████████| 500/500 [03:51<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 6000 to 6500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 6000: 100%|██████████| 500/500 [04:00<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 6500 to 7000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 6500: 100%|██████████| 500/500 [03:55<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 7000 to 7500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 7000: 100%|██████████| 500/500 [04:02<00:00,  2.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 7500 to 8000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 7500: 100%|██████████| 500/500 [03:58<00:00,  2.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 8000 to 8500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 8000: 100%|██████████| 500/500 [03:58<00:00,  2.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 8500 to 9000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 8500: 100%|██████████| 500/500 [04:00<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 9000 to 9500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 9000: 100%|██████████| 500/500 [03:54<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 9500 to 10000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 9500: 100%|██████████| 500/500 [03:50<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 10000 to 10500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 10000: 100%|██████████| 500/500 [03:54<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 10500 to 11000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 10500: 100%|██████████| 500/500 [04:03<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 11000 to 11500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 11000: 100%|██████████| 500/500 [03:57<00:00,  2.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 11500 to 12000\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 11500: 100%|██████████| 500/500 [03:53<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 12000 to 12500\n","output_type":"stream"},{"name":"stderr","text":"Processing batch 12000:   4%|▎         | 18/500 [00:09<04:05,  1.97it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/final_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mprocess_and_save_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataTest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_unit_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mprocess_and_save_batches\u001b[0;34m(dataTest, batch_size, entity_unit_map, output_file)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path):\n\u001b[1;32m     25\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[0;32m---> 26\u001b[0m     res3 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_structured_text3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     fres \u001b[38;5;241m=\u001b[39m extract_value_and_unit(res3, r[\u001b[38;5;241m3\u001b[39m], entity_unit_map)\n\u001b[1;32m     28\u001b[0m     dflist\u001b[38;5;241m.\u001b[39mappend([r[\u001b[38;5;241m0\u001b[39m], fres])\n","Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mextract_structured_text3\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_structured_text3\u001b[39m(image):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     image = preprocess_image3(image)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     print(f'Image: {image.shape}')\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mcraft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     debug_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     debug_image = Image.fromarray(image)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     draw = ImageDraw.Draw(debug_image)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     structured_text \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/craft_text_detector/__init__.py:131\u001b[0m, in \u001b[0;36mCraft.detect_text\u001b[0;34m(self, image, image_path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     image \u001b[38;5;241m=\u001b[39m image_path\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# perform prediction\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcraft_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcraft_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefine_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlong_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# arange regions\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/craft_text_detector/predict.py:80\u001b[0m, in \u001b[0;36mget_prediction\u001b[0;34m(image, craft_net, refine_net, text_threshold, link_threshold, low_text, cuda, long_size, poly)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch_utils\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     79\u001b[0m         y_refiner \u001b[38;5;241m=\u001b[39m refine_net(y, feature)\n\u001b[0;32m---> 80\u001b[0m     score_link \u001b[38;5;241m=\u001b[39m \u001b[43my_refiner\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     81\u001b[0m refinenet_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m     82\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"t = pd.read_csv('/kaggle/working/final_output.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:17:40.377803Z","iopub.execute_input":"2024-09-16T06:17:40.378351Z","iopub.status.idle":"2024-09-16T06:17:40.392557Z","shell.execute_reply.started":"2024-09-16T06:17:40.378282Z","shell.execute_reply":"2024-09-16T06:17:40.391466Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"t","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:17:43.839709Z","iopub.execute_input":"2024-09-16T06:17:43.840106Z","iopub.status.idle":"2024-09-16T06:17:43.862942Z","shell.execute_reply.started":"2024-09-16T06:17:43.840070Z","shell.execute_reply":"2024-09-16T06:17:43.862005Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       index            prediction\n0          0          (None, None)\n1          1  (42.0, 'centimetre')\n2          2  (42.0, 'centimetre')\n3          3  (42.0, 'centimetre')\n4          4  (90.0, 'centimetre')\n...      ...                   ...\n11995  12007  (30.0, 'centimetre')\n11996  12008  (30.0, 'centimetre')\n11997  12009          (None, None)\n11998  12010          (None, None)\n11999  12011        (1.97, 'inch')\n\n[12000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>(None, None)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>(42.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>(42.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>(42.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>(90.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11995</th>\n      <td>12007</td>\n      <td>(30.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>11996</th>\n      <td>12008</td>\n      <td>(30.0, 'centimetre')</td>\n    </tr>\n    <tr>\n      <th>11997</th>\n      <td>12009</td>\n      <td>(None, None)</td>\n    </tr>\n    <tr>\n      <th>11998</th>\n      <td>12010</td>\n      <td>(None, None)</td>\n    </tr>\n    <tr>\n      <th>11999</th>\n      <td>12011</td>\n      <td>(1.97, 'inch')</td>\n    </tr>\n  </tbody>\n</table>\n<p>12000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_file = '/kaggle/working/final_output.csv'\nstart_idx = 12011\n\nremaining_data = dataTest[start_idx:]\n\nremaining_df = pd.DataFrame({\n    'index': [r[0] for i, r in remaining_data.iterrows()],\n    'prediction': [''] * len(remaining_data)\n})\n\nremaining_df.to_csv(output_file, index=False, mode='a', header=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:19:05.425227Z","iopub.execute_input":"2024-09-16T06:19:05.425990Z","iopub.status.idle":"2024-09-16T06:19:13.629903Z","shell.execute_reply.started":"2024-09-16T06:19:05.425950Z","shell.execute_reply":"2024-09-16T06:19:13.629089Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your data from the CSV (or you may already have it in a DataFrame)\ndf = pd.read_csv('/kaggle/working/final_output.csv')\n\n# Function to convert the prediction\ndef format_prediction(pred):\n    try:\n        value, unit = eval(pred)  # Convert string to tuple (if stored as string)\n        if value is None or unit is None:\n            return \"\"  # If either value or unit is None, return empty string\n        else:\n            return f\"{value} {unit}\"  # Convert to \"value unit\"\n    except:\n        return \"\"  # In case of any issues, return empty string\n\n# Apply the conversion function to the 'prediction' column\ndf['prediction'] = df['prediction'].apply(format_prediction)\n\n# Save the updated DataFrame back to CSV\ndf.to_csv('/kaggle/working/final_output0.csv', index=False)\n\nprint(\"Predictions have been converted and saved.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:21:11.676388Z","iopub.execute_input":"2024-09-16T06:21:11.676819Z","iopub.status.idle":"2024-09-16T06:21:12.148970Z","shell.execute_reply.started":"2024-09-16T06:21:11.676752Z","shell.execute_reply":"2024-09-16T06:21:12.148033Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Predictions have been converted and saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataTest['index']","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:23:33.037760Z","iopub.execute_input":"2024-09-16T06:23:33.038650Z","iopub.status.idle":"2024-09-16T06:23:33.046202Z","shell.execute_reply.started":"2024-09-16T06:23:33.038605Z","shell.execute_reply":"2024-09-16T06:23:33.045227Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0              0\n1              1\n2              2\n3              3\n4              4\n           ...  \n131182    131283\n131183    131284\n131184    131285\n131185    131286\n131186    131287\nName: index, Length: 131187, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = pd.read_csv('/kaggle/working/final_output0.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:32:03.750692Z","iopub.execute_input":"2024-09-16T06:32:03.751113Z","iopub.status.idle":"2024-09-16T06:32:03.784897Z","shell.execute_reply.started":"2024-09-16T06:32:03.751075Z","shell.execute_reply":"2024-09-16T06:32:03.783958Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Assuming 'dataTest' contains the 'index' column and 't' is the DataFrame we are working with\ndataTest_len = len(dataTest)\nt_len = len(t)\n\n# Check if t is shorter and needs padding with NaN\nif t_len < dataTest_len:\n    # Create a DataFrame of NaN to append\n    extra_rows = pd.DataFrame({'index': [np.nan] * (dataTest_len - t_len), 'prediction': [np.nan] * (dataTest_len - t_len)})\n    # Append the extra rows to t\n    t = pd.concat([t, extra_rows], ignore_index=True)\n\n# Replace all 'index' values in t with dataTest['index']\nt['index'] = dataTest['index'].values\n\n# Ensure only 'index' and 'prediction' columns are present\nt = t[['index', 'prediction']]\n\nt = t.set_index('index')\n\n# Save the DataFrame without the default index (i.e., no extra index column in the CSV)\nt.to_csv('/kaggle/working/final_output1.csv', index=False)\n\nprint(\"File saved successfully with 'index' replaced and lengths matched.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:34:16.276521Z","iopub.execute_input":"2024-09-16T06:34:16.276975Z","iopub.status.idle":"2024-09-16T06:34:16.360186Z","shell.execute_reply.started":"2024-09-16T06:34:16.276929Z","shell.execute_reply":"2024-09-16T06:34:16.359275Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"File saved successfully with 'index' replaced and lengths matched.\n","output_type":"stream"}]},{"cell_type":"code","source":"len(dataTest) , len(t)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:30:33.820613Z","iopub.execute_input":"2024-09-16T06:30:33.821007Z","iopub.status.idle":"2024-09-16T06:30:33.828151Z","shell.execute_reply.started":"2024-09-16T06:30:33.820968Z","shell.execute_reply":"2024-09-16T06:30:33.827034Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(131187, 131176)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:30:19.130245Z","iopub.execute_input":"2024-09-16T06:30:19.130635Z","iopub.status.idle":"2024-09-16T06:30:19.136610Z","shell.execute_reply.started":"2024-09-16T06:30:19.130596Z","shell.execute_reply":"2024-09-16T06:30:19.135708Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"131176"},"metadata":{}}]},{"cell_type":"code","source":"df_len = len(t)\ndataTest_len = len(dataTest['index'])\n\nif df_len > dataTest_len:\n    # Replace the 'index' in df with dataTest['index'] values\n    t.loc[:dataTest_len-1, 'index'] = dataTest['index'].values\n    # Fill the remaining rows with empty or NaN for 'index'\n    t.loc[dataTest_len:, 'index'] = np.nan\nelif df_len < dataTest_len:\n    # Replace 'index' only up to the length of df\n    t['index'] = dataTest['index'].values[:df_len]\n\n# Save the updated DataFrame to CSV\nt.to_csv('/kaggle/working/final_output0.csv', index=False)\n\nprint(\"Index has been replaced and the DataFrame saved.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T06:26:51.407465Z","iopub.execute_input":"2024-09-16T06:26:51.408336Z","iopub.status.idle":"2024-09-16T06:26:51.551614Z","shell.execute_reply.started":"2024-09-16T06:26:51.408292Z","shell.execute_reply":"2024-09-16T06:26:51.550686Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Index has been replaced and the DataFrame saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"data = {'index': [f'{i}' for i in dataTest.iloc[:,0]], 'prediction': [\"\"] * len(dataTest)}","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:27:35.472291Z","iopub.execute_input":"2024-09-16T04:27:35.472687Z","iopub.status.idle":"2024-09-16T04:27:35.518820Z","shell.execute_reply.started":"2024-09-16T04:27:35.472649Z","shell.execute_reply":"2024-09-16T04:27:35.517877Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(data)\ndata.to_csv('/kaggle/working/output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T04:27:38.248232Z","iopub.execute_input":"2024-09-16T04:27:38.248987Z","iopub.status.idle":"2024-09-16T04:27:38.397539Z","shell.execute_reply.started":"2024-09-16T04:27:38.248947Z","shell.execute_reply":"2024-09-16T04:27:38.396650Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import random\nimport pytesseract\n\ni = random.randint(0,len(df)-1)\n# i = 133 , 714, 460 , 480 , 141(err) , 166(blank) , 753(rot) , 529(rot) , 362(fres bad) , 750(err)\ni = 422\n# goodres: 423 , 69 , 529\nprint(f'I: {i}')\nrow = df.iloc[i,:]\n# for i,r in df[:10].iterrows():\nimg_path = df.iloc[i,0].split('/')[-1]\n# img_path = '41-GUSWgzWL.jpg'\nimg = Image.open(f'/kaggle/input/imagestrain/sampleTrain/{img_path}')\nif img:\n    res3 = extract_structured_text3(np.array(img))\n#     res = extract_structured_text(np.array(img))\n    res2 = filterNum3(reader.readtext(img, detail=0))\n#     res4 = pytesseract.image_to_string(img, lang='eng').strip()\n\nprint('_'*40)\n# print(f'result: {res}')\nprint(f'EasyOCR rawdog: {res2}')\nprint(f'CRAFT: {res3}')\n# print(f'PyTess: {res4.strip()}')\nprint(f'Entity_value: {row}')\nprint('_'*100)\nprint('_'*100)\nfres = extract_value_and_unit(res3,row[2],entity_unit_map)\nfres =[str(i) for i in fres]\n# fres = model(res, row[1],row[2])\n# print(f'fres: {model.tokenizer.decode(fres)}')\nprint(f'fres: {\" \".join(fres)}')\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:32:35.701352Z","iopub.execute_input":"2024-09-16T02:32:35.702069Z","iopub.status.idle":"2024-09-16T02:32:36.774309Z","shell.execute_reply.started":"2024-09-16T02:32:35.702028Z","shell.execute_reply":"2024-09-16T02:32:36.773245Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"I: 422\n________________________________________\nEasyOCR rawdog: ['12CM', '15CM']\nCRAFT: ['12CM', '15CM']\nEntity_value: image_link      https://m.media-amazon.com/images/I/31sYol1Xny...\ngroup_id                                                   752266\nentity_name                                                height\nentity_value                                      12.0 centimetre\nimage_name                                        31sYol1XnyL.jpg\nName: 184450, dtype: object\n____________________________________________________________________________________________________\n____________________________________________________________________________________________________\nfres: 12.0 centimetre\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x79f2114f93c0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"fres","metadata":{"execution":{"iopub.status.busy":"2024-09-16T01:07:11.733583Z","iopub.execute_input":"2024-09-16T01:07:11.734599Z","iopub.status.idle":"2024-09-16T01:07:11.740814Z","shell.execute_reply.started":"2024-09-16T01:07:11.734555Z","shell.execute_reply":"2024-09-16T01:07:11.739754Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"['7', '.', '0', ' ', 'i', 'n', 'c', 'h', 'e', 's']"},"metadata":{}}]},{"cell_type":"code","source":"plt.imshow(debug_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_file):\n    if image_file.startswith(\"http://\") or image_file.startswith(\"https://\"):\n        response = requests.get(image_file)\n        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    else:\n        image = Image.open(image_file).convert(\"RGB\")\n    return image\nimage = load_image(\"https://m.media-amazon.com/images/I/31rKphtJBjS.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result: [[[[638.0, 1085.0], [715.0, 1089.0], [714.0, 1113.0], [637.0, 1109.0]], [[564.0, 1054.0], [791.0, 1061.0], [790.0, 1089.0], [564.0, 1083.0]], [[567.0, 980.0], [789.0, 987.0], [788.0, 1017.0], [566.0, 1009.0]], [[574.0, 943.0], [781.0, 948.0], [780.0, 978.0], [574.0, 973.0]], [[613.0, 882.0], [747.0, 882.0], [747.0, 939.0], [613.0, 939.0]], [[578.0, 796.0], [804.0, 794.0], [804.0, 839.0], [578.0, 841.0]]]]\n# Entity_value: image_link      https://m.media-amazon.com/images/I/41adaWndLM...\n# group_id                                                   254449\n# entity_name                                           item_volume\n# entity_value                                      30.0 millilitre\n# image_name                                        41adaWndLML.jpg\n# Name: 3907, dtype: object\n","metadata":{},"execution_count":null,"outputs":[]}]}